{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c47629a",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://tensorflowkorea.files.wordpress.com/2020/12/4.-e18492e185a9e186abe1848ce185a1-e18480e185a9e186bce18487e185aee18492e185a1e18482e185b3e186ab-e18486e185a5e18489e185b5e186abe18485e185a5e18482e185b5e186bce18483e185b5e186b8e18485e185a5e.png?w=972\" width=\"250\" height=\"250\"><br>\n",
    "</center>\n",
    "\n",
    "\n",
    " - (https://bit.ly/hg-09-1)\n",
    " - (https://bit.ly/hg-09-2)\n",
    " - (https://bit.ly/hg-09-3)\n",
    " \n",
    "\n",
    "# Chapter09. 텍스트를 위한 인공 신경망 ( 댓글은 분석하라!)\n",
    "\n",
    "- 학습목표\n",
    "    - 텍스트와 시계열 데이터와 같은 순차 데이터에 잘 맞는 신경망의 개념과 구성 요소에 대해 배운다\n",
    "    - 케라스 API로 기본적인 순환 신경망에서 고급 순환 신경망을 만들어 영화 감상평을 분류하는 작업에 적용해 본다.\n",
    "    - 순환 신경망에서 발생하는 문제점과 이를 극복하기 위한 해결책을 살펴본다.\n",
    "    \n",
    "    \n",
    "## 09-1 순차 데이터와 순환 신경망\n",
    "\n",
    "- 핵심 키워드\n",
    "    - 순차 데이터\n",
    "    - 순환 신경망\n",
    "    - 셸\n",
    "    - 은닉 상태\n",
    "    - 순차 데이터의 특징을 알고 순환 신경망의 개념을 학습한다.\n",
    "    \n",
    "#### 문제 상황\n",
    "\n",
    "상품 페이지의 수많은 댓글을 일일이 확인하기 어렵다. 설령 마케팅 팀의 모든 직원이 나눠서 확인하더라도 사람마다 댓글의 좋고 나쁨을 가르는 기준이 달라서 이또한 문제이다.\n",
    "\n",
    "\n",
    "### 순차 데이터\n",
    "\n",
    "**순차 데이터 sequential data**는 텍스트나 **시계열 데이터 time seires data** 와 같이 순서에 의미가 깅ㅆ는 데이터를 말한다. 예를 들어 \"I am a boy\"는 쉽게 이해 할수 있지만 \"boy am a I\"는 말이 되지 않는다. 또 일별 온도를 기록한 데이터에서 날짜 순서를 뒤죽박죽 섞는다면 내일의 온도르르 쉽게 예상하기 어렵다.\n",
    "\n",
    "지금까지 우리가 보았던 데이터는 순서와는 상관이 없다. 예로 패션 MNIST 데이터를 생각해보자. 이 데이터를 신경망 모델에 전달할 때 샘플을 랜덤하게 섞은 후 훈련 세트와 검증 세트로 나누었다. 즉 샘플의 순서와 전혀 상관이 없다. 심지어 골고루 섞는 편이 결과가 더 좋다.\n",
    "\n",
    "이는 딥러닝뿐만 아니라 일반적인 머신러닝 모델에서도 마찬가지이다. 4장에서 봤던 생선 데이터나 패션 MNIST 데이터는 어떤 샘플이 먼저 주입되어도 모델의 학습에 큰 영향을 미치지 않는다.\n",
    "\n",
    "이 장에서 사용하려는 댓글, 즉 텍스트 데이터는 단어의 순서가 중요한 순차 데이터이다. 이런 데이터는 순서를 유지하며 신경망에 주입해야 한다. 단어의 순서를 마구 섞어서 주입하면 안된다.\n",
    "\n",
    "따라서 순차 데이터를 다룰 때는 이전에 입력한 데이터를 기억하는 기능이 필요하다. 예를 들어 \"별로지만 추천해요\" 에서 \"추천해요\"가 입력될 때 \"별로지만\"을 기억하고 있어야 이 댓글을 무조건 긍정적이라고 판단하지 않을 것이다.\n",
    "\n",
    "완전 연결 신경망이나 합성곱 신경망은 이런 기억 장치가 없다. 하나의 샘플(또는 하나의 배치)을 사용하여 정방향 계산을 수행하고 나면 그 샘플은 버려지고 다음 샘플을 처리할 때 재사용하지 않습니다. 이렇게 입력 데이터의 흐름이 앞으로만 전달되는 신경망을 **피드포워드 신경망 feedforward neural network FFNN**이라고 한다. 이전 장에서 배웠던 완전 연결 신경망과 합성곱 신경망이 모두 피드포워드 신경망에 속한다.\n",
    "\n",
    "신경망이 이전에 처리했던 샘플을 다음 샘플을 처리하는데 재사용하기 위해서는 이렇게 데이터 흐름이 앞으로만 전달되어서는 곤란하다. 다음 샘플을 위해서 이전 데이터가 신경망 층에 순환될 필요가 있다. 이런 신경망이 바로 순환 신경망이다.\n",
    "\n",
    "### 순환 신경망\n",
    "\n",
    "**순환 신경망 recurrent neural network, RNN**은 일반적인 완전 연결 신경망과 거의 비슷하다. 완전 연결 신경망에 이전 데이터의 처리 흐름을 순환하는 고리 하나만 추가하면 된다. \n",
    "\n",
    "그래서 순환 신경망에서는 '이전 샘플에 대한 기억을 가지고 있다'고 종종 말한다. 이렇게 샘플을 처리하는 한 단계를 **타임스텝 timestep**이라고 말한다. 순환 신경망은 이전 타임스텝의 샘플을 기억하지만 타임스텝이 오래 될수록 순환되는 정보는 희미해 진다. 나중에 여기에 대해서 다시 자세히 언급하겠다.\n",
    "\n",
    "순환 신경망에는 특별히 층을 **셀 cell** 이라고 부른다. 한 셀에는 여러 개의 뉴런이 있지만 완전 연결 신경망과 달리 뉴런을 모두 표시하지 않고 하나의 셀로 층을 표현한다. 또 셀의 출력을 **은닉 상태 hidden state**라고 부른다.\n",
    "\n",
    "합성곱 신경망에서처럼 신경망의 구조마다 조금씩 부르는 이름이 다를 수 있다. 하지만 기본 구조는 같다. 입력에 어떤 가중치를 곱하고 활성화 함수를 통과시켜 다음 층으로 보내는 거다. 달라지는 것은 츠으이 출력(즉 은닉 상태)을 다음 타임 스텝에 재사용한다는 것 뿐이다.\n",
    "\n",
    "일반적으로 은닉층의 활성화 함수로는 하이퍼볼릭 탄젠트 hyperbolic tangent 함수인 tanh가 많이 사용된다. tanh함수도 S자 모양을 띠기 때문에 종종 시그모이드 함수라고 부르기도 한다. 하지만 헷갈릴 수 있으니 이 책에서는 이렇게 부르지 않겠다. tanh함수는 시그모이드 함수와는 달리 -1 ~ 1 사이의 범위를 가진다.\n",
    "\n",
    "다른 신경망과 마찬가지로 순환 신경망 그림에도 번거로움을 피하기 위해 활성화 함수를 표시하지 않는 경우가 많다. 하지만 순환 신경망에서도 활성화 함수가 반드시 필요하다는 것을 꼭 기억하자.\n",
    "\n",
    "합성곱 신경망과 같은 피드포워드 신경망에서 뉴런은 입력과 가중치를 곱한다. 순환 신경망에서도 동일하다. 다만 순환 신경망의 뉴런은 가중치가 하나 더 있다. 바로 이전 타임스텝의 은닉 상태에 곱해지는 가중치이다. 셀은 입력과 이전 타입스텝의 은닉 상태를 사용하여 현재 타임스텝의 은닉 상태를 만든다.\n",
    "\n",
    "\n",
    "### 셀의 가중치와 입출력\n",
    "\n",
    "순환 신경망의 셀에서 필요한 가중치 크기를 계산해 보겠다. 복잡한 모델을 배울수록 가중치 개수를 계산해 보면 잘 이해하고 알 수 있다. 예를 들어 다음 그림처럼 순환층에 입력되는 특성의 개수가 4개이고 순환층의 뉴런이 3개라고 가정해 보자. 먼저 Wx의 크기를 구해보자. 입력층과 순환층의 뉴런이 모두 완전 연결되기 때문에 가중치 Wx의 크기는 4 x 3 = 12개가 된다. 7장에서 본 완전 연결 신경망의 입력층과 은닉층의 연결과 같다. 그럼 순환층에서 다음 타임스텝에 재사용되는 은닉 상태를 위한 가중치 Wb의 크기는 어떻게 될까?\n",
    "\n",
    "순환층에 있는 첫 번째 뉴런(r1)의 은닉 상태가 다음 타임스텝에 재사용될 때 첫 번째 뉴런과 두 번째, 세 번째 뉴런에 모두 전달 된다. 위 그림에서 붉은색으로 표시했다. 즉 이전 타임스텝의 은닉 상태는 다음 타임스텝의 뉴런에 완전히 연결된다.\n",
    "\n",
    "두 번째 뉴런의 은닉 상태도 마찬가지로 첫 번째 뉴런과 두 번째 뉴런, 세 번째 뉴런에 모두 전달되고(파란 화살표), 세 번째 뉴런의 은닉 상태도 동일하다(검은 화살표). 따라서 이 순한층에서 은닉 상태를 위한 가중치 W3는 3 x 3 = 9 개이다. 가중치는 모두 구했으니 모델 파라미터 개수를 계산해 보자. 가중치에 절편을 더하면 된다. 여기엔 각 뉴런마다 하나의 절편이 있다. 따라서 이 순환층은 모두 12 + 9 + 3 =24개의 모델 파라미터를 가지고 있다. 이제 왜 순환층을 셀 하나로 표시할 수밖에 없는지 이해가 됬을 것이다. 은닉 상태가 모든 뉴런에 순환되기 때문에 완전 연결 신경망처럼 그림으로 표현하기는 너무 어렵다.\n",
    "\n",
    "- 모델 파라미터 수 = Wx + Wb + 절편 = 12 + 9 + 3 = 24\n",
    "\n",
    "순환층의 가중치 크기를 알아보았으므로 이번에는 순환층의 입력과 출력에 대해 생각해 보자. 이전 장에서 배웠던 합성곱 층의 입력은 전형적으로 하나의 샘플이 3개의 차원을 가진다. 너비, 높이, 채널이다. 입력이 합성곱 층과 풀링 층을 통과하면 너비,높이,채널(혹은 깊이)의 크기가 달라지지만 차원의 개수는 그대로 유지되었다.\n",
    "\n",
    "순환층은 일반적으로 샘플마다 2개의 차원을 가진다. 보통 하나의 샘플을 하나의 시퀀스 sequence라고 말한다. 시퀀스 안에는 여러 개의 아이템이 들어 있다. 여기에서 시퀀스의 길이가 바로 타임스텝 길이가 된다.\n",
    "\n",
    "예를 들어 어떤 샘플에 \"I am a boy\" 란 문장이 들어 있다고 가정해 보자. 이 샘플은 4개의 단어로 이루어져 있다. 각 단어를 3개의 어떤 숫자로 표현한다고 가정해 보자.( 이 숫자 표현에 대해서는 다음 절에 자세히 다루겠다.)\n",
    "\n",
    "이런 입력이 순환층을 통과하면 두 번째, 세 번째 차원이 사라지고 순환층의 뉴런 개수만큼 출력된다. 이를 차근차근 설명해 보겠다. 하나의 샘플은 시퀀스 길이(여기서에서는 단어 개수) 와 단어표현(다음 절에서 다룬다)의 2차원 배열이다. 순환층을 통과하면 1차원 배열로 바뀐다. 이 1차원 배열의 크기는 순환층의 뉴런 개수에 의해 결정된다. 셀이 모든 타입스텝에서 출력을 만든 것처럼 표현했다. 하지만 사실 순환층은 기본적으로 마지막 타임스텝의 은닉 상태만 출력으로 내보낸다.\n",
    "\n",
    "마지막으로 출력층의 구성에 대해 알아보겠다. 합성곱 신경망과 마찬가지로 순환 신경망도 마지막에는 밀집층을 두어 클래스를 분류한다. 다중 분류일 경우에는 출력층에 클래스 개수만큼 뉴런을 두고 소프트맥스 활성화 함수를 사용한다. 이진 분류일 경우에는 하나의 뉴런을 두고 시그모이드 활성화 함수를 사용한다.\n",
    "\n",
    "\n",
    "### 순환 신경망으로 순환 데이터 처리 - 문제해결 과정\n",
    "\n",
    "이번 절에서 순차 데이터와 순환 신경망을 소개했다. 먼저 순차 데이터의 특징을 예를 들어 소개했고 순환 신경망의 개념과 주요 구성 요소를 소개했다. 여기에는 순환층, 셀, 은닉 상태 등이 포함된다.\n",
    "\n",
    "순환층은 순서를 가진 데이터를 처리하기 위해 밀집 신경망이나 합성곱 신경망과는 계산하는 방식이 다르다. 은닉층의 출력을 다음 층으로만 보내지 않고 다음 순서에 다시 재사용하는 순환 구조로 되어 있다.\n",
    "\n",
    "하지만 거시적인 구조는 다른 신경망과 크게 다르지 않다. 입력에 가중치를 곱하고 절편을 더한 다음 활서화 함수를 통과시켜 다음 층으로 전달하는 것이다. 다만 순환층은 이전 타임스텝의 출력을 입력으로 함께 사용한다. 또 마지막 타임스텝의 출력만 다음 층으로 전달하다는 것을 잊지 말자.\n",
    "\n",
    "다음 절에서는 템서플로와 케라스를 사용해 순차 데이터와 순환 신경망을 직접 만들어 영화 감상평을 긍정과 부정으로 분류해보겠다.\n",
    "\n",
    "## 09-2 순환 신경망으로 IMDB 리뷰 분류하기\n",
    "\n",
    "- 핵심키워드\n",
    "    - 말뭉치\n",
    "    - 토큰\n",
    "    - 원-핫 인코딩\n",
    "    - 단어 임베딩\n",
    "    - 텐서플로를 사용해 순환 신경망을 만들어 영화 리뷰 데이터셋에 적용해서 리뷰를 긍정과 부정으로 분류한다.\n",
    "    \n",
    "1절에서 순환 신경망의 작동 원리를 살펴보았다. 이번 절에서는 대표적인 순환 신경망 문제인 IMDB 리뷰 데이터셋을 사용해 가장 간단한 순환 신경망 모델을 훈련해 보겠다.\n",
    "\n",
    "이 데이터셋을 두 가지 방법으로 변형하여 순환 신경망에 주입해보겠다. 하나는 원-핫 인코딩 이고 또 다른 하나는 단어 임베딩이다. 이 두 가지 방법의 차이점에 대해 설명하고 순환 신경망을 만들 때 고려해야 할 점을 알아보겠다.\n",
    "\n",
    "그럼 먼저 이 절에서 사용할 IMDB 리뷰 데이터셋을 적재해 보겠다.\n",
    "\n",
    "### IMDB 리뷰 데이터셋\n",
    "\n",
    "IMDB 리뷰 데이터셋은 유명한 인터넷 영화 데이터베이스인 imdb.com에서 수집한 리뷰를 감상평에 따라 긍정과 부정으로 분류해 놓은 데이터셋이다. 총 50,000개의 샘플로 이루어져 있고 훈련 데이터와 테스트 데이터에 각각 25,000개씩 나누어져 있다.\n",
    "\n",
    "- 자연어 처리와 말뭉치란 무엇인가?\n",
    "    - 자연어 처리(natural language processing, NLP)는 컴퓨터를 사용해 인간의 언어를 처리하는 분야이다. 대표적인 세부 분야로는 음성 인식, 기계번역, 감성 분석등이 있다. IMDB 리뷰를 감성평에 따라 분류하는 작업은 감성 분석에 해당한다. 자연어 처리 분야에서는 훈련 데이터를 종종 **말뭉치 corpus**라고 부른다. 예를 들어 IMDB 리뷰 데이터셋이 하나의 말뭉치 이다.\n",
    "    \n",
    "사실 텍스트 자체를 신경망에 전달하지는 않는다. 컴퓨터에서 처리하는 모든 것은 어떤 숫자 데이터이다. 앞서합성곱 신경망에서 이미지를 다룰 때는 특별한 변환을 하지 않는다. 이미지가 정수 픽셀값으로 이루어져 있기 때문이다. 텍스트 데이터의 경우 단어를 숫자 데이터로 바꾸는 일반적인 방법은 데이터에 등장하는 단어마다 고유한 정수를 부여하는 것이다. \n",
    "\n",
    "예를들어 'he'를 10으로 매핑하고 'cat'을 13에 매핑하더라고 'cat'이 'he'보다 좋거나 크다는 뜻이 아니다. 이 정숫값 사이에는 어떤 관계도 없다. 일반적으로 영어 문장은 모두 소문자로 바꾸고 구둣점을 삭제한 다음 공백을 기준으로 분리한다. 이렇게 분리된 단어를 **토큰 token**이라고 부른다. 하나의 샘플은 여러 개의 토큰으로 이루어져 있고 1개의 토큰이 하나의 타임스탬프에 해당한다.\n",
    "\n",
    "- 간단한 문제라면 영어 말뭉치에서 토큰을 단어와 같게 봐도 좋다. 한국어는 조금 다르다.\n",
    "\n",
    "- 한글 문장은 어떻게 토큰을 분리하나요?\n",
    "    - 한글은 조사가 발달되어 있기 때문에 공백으로 나누는 것만으로 부족하다. 일반적으로 한글은 형태소 분석을 통해 토큰을 만든다. KoNLPy를 참고\n",
    "\n",
    "\n",
    "토큰에 할당하는 정수 중에 몇 개는 특정한 용도로 예약되어 있는 경우가 많다. 예를 들어 0은 패딩, 1은 문장의 시작, 2는 어휘 사전에 없는 토큰을 나타낸다.\n",
    "\n",
    "- 어휘 사전은 무엇인가?\n",
    "    - 훈련 세트에서 고유한 단어를 뽑아 만든 목록을 어휘 사전이라고 말한다. 예를 들어 테스트 세트 안에 어휘 사전에 없는 단어가 있다면 2로 변환하여 신경망 모델에 주입한다.\n",
    "    \n",
    "실제 IMDB 리뷰 데이터셋은 영어로 된 문장이지만 편리하게도 텐서플로에는 이미 정수로 바꾼 데이터가 포함되어있다. tensorflow.keras.datasets 패키지 아래 imdb 모듈을 임포트하여 이 데이터를 적재해 보겠다. 여기에서는 전체 데이터셋에서 가장 자주 등장하는 단어 500개만 사용하겠다. 이렇게 하기 위해 load_data() 함수의 num_words 매개변수를 500으로 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "818802da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/keras/datasets/imdb.py:128: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/keras/datasets/imdb.py:129: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "(train_input, train_target), (test_input, test_target) = imdb.load_data ( num_words=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e9bea0",
   "metadata": {},
   "source": [
    "먼저 훈련 세트와 테스트 세트의 크기를 확인해 보겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c9d7000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape, test_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133028a3",
   "metadata": {},
   "source": [
    "앞서 말했듯이 이 데이터셋은 훈련 세트와 테스트 세트가 각각 25,000 개의 샘플로 이루어져 있다. 그런데 배열이 1차원인 게 이상하지 않나? IMDB 리뷰 텍스트는 길이가 제각각이다. 따라서 고정 크기의 2차원 배열에 담기 보다는 리뷰마다 별도의 파이썬 리스트로 담아야 메모리르 효율적으로 사용할 수 있다. 즉 앞의 그림처럼 이 데이터는 개별 리뷰를 담은 파이썬 리스트 객체로 이루어진 넘파이 배여이다.\n",
    "\n",
    "넘파이 배열은 정수가 실수 외에도 파이썬 객체를 담을 수 있다. 그럼 다음과 같이 첫 번째 리뷰의 길이를 출력해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea9e27fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n"
     ]
    }
   ],
   "source": [
    "print(len((train_input[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c9dd27",
   "metadata": {},
   "source": [
    "첫 번째 리뷰의 길이는 218개의 토큰으로 이루어져 있다. 두 번째 리뷰의 길이를 확인해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e68172a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n"
     ]
    }
   ],
   "source": [
    "print(len(train_input[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cdb5ed",
   "metadata": {},
   "source": [
    "몇 개 더 핼 술도 있겠지만 리뷰마다 각각 길이가 다르다. 여기서 하나의 리뷰가 하나의 샘플이 된다. 서로 다른 길이의 샘플을 어떻게 신경망에 전달하는지 잠시 후 살펴본다. 이제 첫 번째 리뷰에 담긴 내용을 출력해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbb8cad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(train_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1d96be",
   "metadata": {},
   "source": [
    "앞서 설명했듯이 텐서플로에 있는 IMDB 리뷰 데이터는 이미 정수로 변환되어 있다. 앞서 num_words=500으로 지정했기 때문에 어휘 사전에는 500개의 단어만 들어가 있다. 따라서 어휘 사전에 없는 단어는 모두 2로 표시 되어 나타난다.\n",
    "\n",
    "- 어떤 기준으로 500개의 단어를 고른것인가?\n",
    "    - imdb.load_data() 함수는 전체 어휘 사전에 있는 단어를 등장 횟수 순서대로 나열한 다음 가장 많이 등장한 500개의 단어를 선택한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db037922",
   "metadata": {},
   "source": [
    "이번에는 타깃 데이터를 출력해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b400fc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_target[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e87378",
   "metadata": {},
   "source": [
    "해결할 문제는 리뷰가 긍정인지 부정인지를 판단하는 거다. 그러면 이진 분류 문제로 볼 수 있으므로 타깃값이 0(부정)과 1(긍정)로 나누어진다. \n",
    "\n",
    "데이터를 더 살펴보기 전에 훈련 세트에서 검증 세트를 떼어 놓도록 하자. 원래 훈련 세트의 크기가 25,000개였으므로 20%를 검증 세트로 떼어 놓으면 훈련 세트의 크기는 20,000개로 줄어들 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f0135b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_input, val_input, train_target, val_target = train_test_split (train_input, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6074d481",
   "metadata": {},
   "source": [
    "이제 훈련 세트에 대해 몇 가지 조사를 해 보겠다. 먼저 각 리뷰의 길이를 계산해 넘파이 배열에 담자. 이렇게 하는 이유는 평균적인 리뷰의 길이와 가장 짧은 리뷰의 길이 그리고 가장 긴 리뷰의 길이를 확인하고 싶기 때문이다. 이를 위해 넘파이 리스트 내포를 사용해 train_input의 원소를 순회하면서 길이를 재도록 하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c89a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "lengths = np.array([len(x) for x in train_input])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb55d6ce",
   "metadata": {},
   "source": [
    "lengths 배열이 준비되었으므로 넘파이 mean() 함수와 mediad() 함수를 사용해 리뷰 길이의 평균과 중간값을 구해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a317c434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239.00925 178.0\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(lengths), np.median(lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08869a65",
   "metadata": {},
   "source": [
    "리뷰의 편균 단어 개수는 239개이고 중간값이 178인 것으로 보아 이 리뷰 길이 데이터는 한쪽에 치우친 분포를 보일 것 같다. lengths  배열을 히스토그램으로 표현해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ba2bdcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(lengths)\n",
    "plt.xlabel('length')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd5afaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
