{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0061a43d",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://tensorflowkorea.files.wordpress.com/2020/12/4.-e18492e185a9e186abe1848ce185a1-e18480e185a9e186bce18487e185aee18492e185a1e18482e185b3e186ab-e18486e185a5e18489e185b5e186abe18485e185a5e18482e185b5e186bce18483e185b5e186b8e18485e185a5e.png?w=972\" width=\"250\" height=\"250\"><br>\n",
    "</center>\n",
    "\n",
    "\n",
    " - (https://bit.ly/hg-03-1)\n",
    " - (https://bit.ly/hg-03-2)\n",
    " - (https://bit.ly/hg-03-3)\n",
    "\n",
    "\n",
    "\n",
    "# Chapter04 다양한 분류 \n",
    "알고리즘 (럭키백의 확률을 계산하라!)\n",
    "\n",
    "- 학습목표\n",
    "    - 로지스틱 회귀, 확률적 경사 하강법과 같은 분류 알고리즘을 배운다.\n",
    "    - 이진 분류와 다중 분류의 차이를 이해하고 클래스별 확률을 예측한다.\n",
    "    \n",
    "## 04-1 로지스틱 회귀\n",
    "\n",
    "- 핵심키워드\n",
    "    - 로지스틱 회귀\n",
    "    - 다중 분류\n",
    "    - 시그모이드 함수\n",
    "    - 소프트맥스 함수\n",
    "    - 로지스틱 회귀 알고리즘을 배우고 이진 분류 문제에서 클래스 확률를 예측한다.\n",
    "    \n",
    "### 럭키백의 확률\n",
    "\n",
    "럭키백은 구성품을 모른 채 먼저 구매하고, 배송받은 다음에야 비로소 구성품을 알 수 있는 상품이다. 책의 예제를 보자. 럭키백에 들어갈 수 있는 생선은 7개라고 알려 주었다. 이 이벤트를 잘 마치려면 럭키백에 들어간 생선의 크기, 무게 등이 주어졌을 때 7개 생선에 대한 확률을 출력해야 한다. 이번에는 길이,높이,두께 외에도 대각선 길이와 무게도 사용할 수 있다.\n",
    "\n",
    "- 이 새과제를 가지고 생각해보자.\n",
    "    - 확률은 숫자니까 회귀 문제인가? 7개의 생선에 대한 문제라면 분류 아닐까? \n",
    "    - k-최근접 이웃은 주변 이웃을 찾아주니까 이웃의 클래스 비율을 확률이라고 출력하면 되지 않을까?\n",
    "    \n",
    "사이킷런의 k-최근접 이웃 분류기도 이와 동일한 방식으로 클래스 확률을 계산하여 제공한다. 그럼 데이터를 준비하고 k-최근접 이웃 분류기로 럭키백에 들어간 생선의 확률을 계산해 보자.\n",
    "\n",
    "> 데이터 준비하기\n",
    "\n",
    "모델 훈련에 사용할 데이터를 만들어 보자. 3장 처럼 판다스를 사용할텐데, 이번에도 인터넷에서 직접 CSV 데이터를 읽어 들일 것이다. 판다스의 read_csv() 함수로 CSV파일을 데이터프레임으로 변환한 다음 head() 메서드로 처음 5개 행을 출력해 보자.\n",
    "\n",
    "- 이 파일 내용을 직접 보고 싶다면 https://bit.ly//fish_csv_data 로 접속하자.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7520b73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diagonal</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bream</td>\n",
       "      <td>242.0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.5200</td>\n",
       "      <td>4.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bream</td>\n",
       "      <td>290.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>31.2</td>\n",
       "      <td>12.4800</td>\n",
       "      <td>4.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bream</td>\n",
       "      <td>340.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.3778</td>\n",
       "      <td>4.6961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bream</td>\n",
       "      <td>363.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>12.7300</td>\n",
       "      <td>4.4555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bream</td>\n",
       "      <td>430.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.4440</td>\n",
       "      <td>5.1340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Species  Weight  Length  Diagonal   Height   Width\n",
       "0   Bream   242.0    25.4      30.0  11.5200  4.0200\n",
       "1   Bream   290.0    26.3      31.2  12.4800  4.3056\n",
       "2   Bream   340.0    26.5      31.1  12.3778  4.6961\n",
       "3   Bream   363.0    29.0      33.5  12.7300  4.4555\n",
       "4   Bream   430.0    29.0      34.0  12.4440  5.1340"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fish = pd.read_csv('https://bit.ly/fish_csv_data')\n",
    "fish.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c999574",
   "metadata": {},
   "source": [
    "- 맨 왼쪽에 0,1,2 와 같은 숫자는 행 번호(판다스의 인덱스)이다. 맨 위에 쓰여진 Species, Weight, Length, Diagonal, Height, Width는 열 제목이다. 판다스는 CSV 파일의 첫 줄을 자동으로 인식해 열 제목으로 만들어 준다.\n",
    "- 데이터프레임이 뭔가요?\n",
    "    - 3장에서도 잠깐 언급했지만 데이터프레임(dataframe)은 판다스에서 제공하는 2차원 표 형식의 주요 데이터 구조이다. 데이터프레임은 넘파이 배열과 비슷하게 열과 행으로 이루어져 있다. 데이터프레임은 통계와 그래프를 위한 메서드를 풍부하게 제공한다. 또 데이터프레임은 넘파이로 상호 변환이 쉽고 사이킷럿과도 잘 호환 된다.\n",
    "    \n",
    "그럼 어떤 종류의 생선이 있는지 Species 열에서 고유한 값을 추출해 보자. 판다스의 unique()함수를 사용하면 간단하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21e83382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bream' 'Roach' 'Whitefish' 'Parkki' 'Perch' 'Pike' 'Smelt']\n"
     ]
    }
   ],
   "source": [
    "print(pd.unique(fish['Species']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340a2163",
   "metadata": {},
   "source": [
    "이 데이터프레임에서 Species 열을 타깃으로 만들고 나머지 5개 열은 입력 데이터로 사용하겠다. 데이터프레임에서 열을 선택하는 방법은 간단하다. 데이터프레임에서 원하는 열을 리스트로 나열하면 된다. Species 열을 빼고 나머지 5개 열을 선택해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bb78e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_input = fish[['Weight', 'Length', 'Diagonal', 'Height', 'Width']].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6379d663",
   "metadata": {},
   "source": [
    "데이터프레임에서 여러 열을 선택하면 새로운 데이터프레임이 반환된다. 이를 to_numpy() 메서드로 넘파이 배열로 바꾸어 fish_input에 저장했다.fish_input에 5개의 특성이 잘 저장되었는지 처음 5개 행을 출력해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "559dea35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[242.      25.4     30.      11.52     4.02  ]\n",
      " [290.      26.3     31.2     12.48     4.3056]\n",
      " [340.      26.5     31.1     12.3778   4.6961]\n",
      " [363.      29.      33.5     12.73     4.4555]\n",
      " [430.      29.      34.      12.444    5.134 ]]\n"
     ]
    }
   ],
   "source": [
    "print(fish_input[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656b21c0",
   "metadata": {},
   "source": [
    "앞에서 fish 데이터프레임을 출력한 값과 비교해보자. 입력 데이터가 잘 준비되었는지 확인했으면 이제 동일한 방식으로 타깃 데이터를 만들자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3539fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_target = fish['Species'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c514ce26",
   "metadata": {},
   "source": [
    "이제 데이터를 훈련 세트와 테스트 세트로 나눈다. 이제 이런 작업이 익숙하게 느껴지면 좋겠다. 2장에서 배웠듯이 머신러닝에서는 기본적으로 데이터 세트 2개가 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bd155c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_input, test_input, train_target, test_target = train_test_split(fish_input, fish_target, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320013fc",
   "metadata": {},
   "source": [
    "그 다음 사이킷런의 StrandardScaler 클래스를 사용해 훈련 세트와 테스트 세트를 표준화 전처리하겠다. 여기에서도 훈련 세트의 통계값으로 테스트 세트를 변환해야 한다는 점을 잊지말자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8187f66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_input)\n",
    "train_scaled = ss.transform(train_input)\n",
    "test_scaled = ss.transform(test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ac6fcf",
   "metadata": {},
   "source": [
    "필요한 데이터를 모두 준비했다. 이제 k-최근접 이웃 분류기로 테스트 세트에 들어 있는 확률을 예측해 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d12023c",
   "metadata": {},
   "source": [
    "> ### k-최근접 이웃 분류기의 확률 예측\n",
    "\n",
    "2장에서 했던 것처럼 사이킷런의 KNeighborsClassifier 클래스 객체를 만들고 훈련 세트로 모델을 훈련한 다음 훈련 세트와 테스트 세트의 점수를 확인해 보겠다. 최근접 이웃 개수인 k를 3으로 지정하여 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b93702f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8907563025210085\n",
      "0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kn = KNeighborsClassifier(n_neighbors = 3)\n",
    "kn.fit(train_scaled, train_target)\n",
    "print(kn.score(train_scaled, train_target))\n",
    "print(kn.score(test_scaled, test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f38c103",
   "metadata": {},
   "source": [
    "여기에서는 클래스 확률을 배우는 것이 목적이므로 훈련 세트와 테스트 세트 점수에 대해서는 잠시 잊도록하자. \n",
    "\n",
    "앞서 fish 데이터프레임에서 7개의 생선이 있었던 것을 기억하나요? 타깃 데이터를 만들 때 fish['Species']를 사용해 만들었기 때문에 훈련 세트와 테스트 세트의 타깃 데이터에서도 7개의 생선 종류가 들어가 있다. 이렇게 타깃 데이터에 2개 이상의 클래스가 포함된 문제를 **다중분류multi-class classification** 라고 부른다.\n",
    "\n",
    "하지만 조금 전 코드에서 보듯이 2장에서 만들었던 이진 분류와 모델을 만들고 훈련하는 방식은 동일하다. 이진 분류를 사용했을 때는 양성 클래스와 음성 클래스를 각각 1과 0으로 지정하여 타깃 데이터를 만들었다. 다중 분류에서도 타깃값을 숫자로 바꾸어 입력할 수 있지만 사이킷런에서는 편리하게도 문자열로 된 타깃값을 그대로 사용할 수 있다.\n",
    "\n",
    "이때 주의할 점이 하나 있다. 타깃값을 그대로 사이킷런 모델에 전달하면 순서가 자동으로 알파벳 순으로 매겨진다. 따라서 pd.unique(fish['Species'])로 출력했던 순서와 다르다. KNeighborsClassifier에서 정렬된 타깃값은 classes_ 속성에 저장되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e5ceb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bream' 'Parkki' 'Perch' 'Pike' 'Roach' 'Smelt' 'Whitefish']\n"
     ]
    }
   ],
   "source": [
    "print(kn.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4905b7dd",
   "metadata": {},
   "source": [
    "'Bream'이 첫 번재 클래스, 'Parkki'가  두 번째 클래스가 되는 식이다. predict() 메서드는 친절하게도 타깃값으로 예측을 출력한다. 테스트 세트에 있는 처음 5개 샘플의 타깃값을 예측해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c62da5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Perch' 'Smelt' 'Pike' 'Perch' 'Perch']\n"
     ]
    }
   ],
   "source": [
    "print(kn.predict(test_scaled[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c07a6c3",
   "metadata": {},
   "source": [
    "이 5개 샘플에 대한 예측은 어떤 확률로 만들어졌을까? 사이킷러의 분류 모델은 pridict_proba() 메서드로 클래스별 확률값을 반환한다. 테스트 세트에 있는 처음 5개 샘플에 대한 확률을 출력해보자. 넘파이 round() 함수는 기본으로 소수점 첫째 자리에서 반올림을 하는데, decimals 매개변수로 유지할 소수점 아래 자릿수를 지정할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f20dc369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.     0.     1.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     1.     0.    ]\n",
      " [0.     0.     0.     1.     0.     0.     0.    ]\n",
      " [0.     0.     0.6667 0.     0.3333 0.     0.    ]\n",
      " [0.     0.     0.6667 0.     0.3333 0.     0.    ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "proba = kn.predict_proba(test_scaled[:5])\n",
    "print(np.round(proba, decimals=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d4133a",
   "metadata": {},
   "source": [
    "predict_proba()메서드의 출력 순서는 앞서 보았던 classes_ 속성과 같다. 즉 첫 번째 열이 'Bream'에 대한 확률, 두 번째 열이 'Parkki'에 대한 확률이다. 이 모델이 계산한 확률이 가장 가까운 이웃의 비율이 맞는지 확인해보자. 네 번째 샘플의 최근접 이웃의 클래스를 확인해 보자.\n",
    "\n",
    "- kneighbors() 메서드의 입력은 2차원 배열이어야한다. 이를 위해 넘파이 배열의 슬라이싱 연산자를 사용했다. 슬라이싱 연산자는 하나의 샘플만 선택해도 항상 2차원 배열이 만들어진다. 여기에서는 네 번째 샘플 하나를 선택했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87c1b61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Roach' 'Perch' 'Perch']]\n"
     ]
    }
   ],
   "source": [
    "distances, indexes = kn.kneighbors(test_scaled[3:4])\n",
    "print(train_target[indexes])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa8cbc1",
   "metadata": {},
   "source": [
    "이 샘플의 이웃은 다섯 번째 클래스인 'Roach'가 1개이고 세 번째 클래스인 'Perch'가 2개이다. 따라서 다섯 번째 클래스에 대한 확률은 1/3=0.3333 이고 세 번째 클래스에 대한 확률은 2/3=0.6667이 된다. 앞서 출력한 네 번째 샘플의 클래스 확률과 같다.\n",
    "\n",
    "성공이다! 아주 쉽게 클래스 확률을 예측했다. 번거로운 계산은 사이킷런이 수행해 주므로 우리는 predict_proba() 메서드를 호출하면 그만이다.그런데 뭔가 좀 이상하다. 잠시 생각해 보니 3개의 최근접 이웃을 사용하기 때문에 가능한 확률은 0/3. 1/3, 2/3, 3/3 이 전부다. 만약 럭키백의 확률을 이렇게만 표시한다면 마케팅팀이 만족하지 않을 것 같다. 확률이라고 말하기 좀 어색하다. 뭔가 더 좋은 방법을 찾아야 할 것 같다.\n",
    "\n",
    "\n",
    "### 로지스틱 회귀\n",
    "\n",
    "**로지스틱 회귀 logistic regression** 는 이름은 회귀이지만 분류 모델이다. 이 알고리즘은 선형 회귀와 동일하게 선형 방정식을 학습한다.확률이 되려면 0~1 또는 0%~ 100%가 사이의 값이 되어야한다. z가 아주 큰 음수일때 0이되고, z가 아주 큰 양수일 때 1이 되도록 바꾸는 방법이 없을까?\n",
    "\n",
    "- 시그모이드 함수 sigmoid function 또는 로지스틱 함수 logistic function 를 사용하면 가능하다.\n",
    "\n",
    "z가 무한하게 큰 음수일 경우 이 함수는 0에 가까워지고, z가 무한하게 큰 양수가 될 때는 1에 가까워진다. z가 0이 될 때는 0.5가 된다. z가 어떤 값이 되더라도 '파이'는 절대로 0 ~ 1사이의 범위를 벗어 날 수 없다. 그렇다면 0 ~ 1 사이 값을 0~100까지 확률로 해석할 수 있다.\n",
    "\n",
    "넘파이를 사용하면 그래프를 간단히 그릴 수 있다. -5와 5사이에 0.1 간격으로 배열 z를 만든 다음 z 위치마다 시그모이드 함수를 계산한다. 지수 함수 계산은 np.exp()함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc64ec71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "z = np.arange(-5, 5, 0.1)\n",
    "phi = 1 / (1 + np.exp(-z))\n",
    "plt.plot(z, phi)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('phi')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119b2585",
   "metadata": {},
   "source": [
    "시그모이드 함수의 출력은 정말 0에서 1까지 변한다. 좋다. 그럼 로지스틱 회귀 모델을 훈련해보자. 이미 예상했겠지만 당연히 사이킷런에는 로지스틱 회귀 모델인 LogisticRegression 클래스가 준비되어 있다. 훈련하기 전에 간단한 이진 분류를 수행해보자. 이진 분류일 경우 시그모이드 함수의 출력이 0.5보다 크면 양성 클래스, 0.5보다 작으면 음성 클래스로 판단한다. 그럼 먼저 도미와 빙어 2개를 사용해서 이진 분류를 수행해 보자.\n",
    "\n",
    "- 딱 0.5일때는 어떻게 되나?\n",
    "    - 정학히 0.5일 때 라이브러리마다 다를 수 있다. 사이킷런은 0.5일때 음성 클래스로 판단한다.\n",
    "    \n",
    "    \n",
    "> ### 로지스틱 회귀로 이진 분류 수행하기\n",
    "\n",
    "넘파이 배열을 True, False 값을 전달하여 행을 선택 할 수 있다. 이를 **불리언 인덱싱 boolean indexing** 이라고 한다. 간단한 예를 보면 금방 이해할 수 있다. 다음과 같이 'A'에서 'E'까지 5개의 원소로 이루어진 배열이 있다. 여기서 'A'와 'C'만 골라내려면 첫 번째와 세 번째 원소만 True이고 나머지 원소는 모두 False인 배열을 전달하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a1d2fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A' 'C']\n"
     ]
    }
   ],
   "source": [
    "char_arr = np.array(['A', 'B', 'C', 'D', 'E'])\n",
    "print(char_arr[[True, False, True, False, False]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b5f602",
   "metadata": {},
   "source": [
    "이와 같은 방식을 사용해 훈련 세트에서 도미(Bream)와 빙어(Smelt)의 행만 골라내겠다. 비교 연산자를 사용하면 도미와 빙어의 행을 모두 True로 만들 수 있다. 예를 들어 도미인 행을 골라내려면 train_target =='Bream'과 같이 쓴다. 이 비교식은 train_target 배열에서 'Bream'인 것은 True이고 그 외는 모두 False인 배열을 반환한다. 도미와 빙어에 대한 비교 결과를 비트 OR 연산자(|)를 사용해 합치면 도미와 빙어에 대한 행만 골라낼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57e669f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bream_smelt_indexes = (train_target == 'Bream') | (train_target == 'Smelt')\n",
    "train_bream_smelt = train_scaled[bream_smelt_indexes]\n",
    "target_bream_smelt = train_target[bream_smelt_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dfbb2e",
   "metadata": {},
   "source": [
    "bream_smelt_indexes 배열은 도미와 빙어일 경우 True이고 그 외는 모두 False 값이 들어가 있다 따라서 이 배열을 사용해 train_scaled와 train_target 배열에 불리언 인덱싱을 적용하면 손쉽게 도미와 빙어 데이터만 골라 낼 수 있다. \n",
    "\n",
    "이제 이 데이터로 로지스틱 회귀 모델을 훈련해보겠다. LogisticRegression 클래스는 선형 모델이므로 sklearn.linear_model 패키지 아래 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd295d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_bream_smelt, target_bream_smelt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51addfe6",
   "metadata": {},
   "source": [
    "훈련한 모델을 사용해 train_bream_smelt에 있는 처음 5개 샘플을 예측해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01353aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bream' 'Smelt' 'Bream' 'Bream' 'Bream']\n"
     ]
    }
   ],
   "source": [
    "print(lr.predict(train_bream_smelt[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7858b6b1",
   "metadata": {},
   "source": [
    "두 번째 샘플을 제외하고 모두 도미로 예측했다. KNeifgborsClassifier와 마찬가지로 예측 확률은 predict_proba() 메서드에서 제공한다. train_bream_smelt에서 처음 5개 샘플의 예측 확률을 출력해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a38d5987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99759855 0.00240145]\n",
      " [0.02735183 0.97264817]\n",
      " [0.99486072 0.00513928]\n",
      " [0.98584202 0.01415798]\n",
      " [0.99767269 0.00232731]]\n"
     ]
    }
   ],
   "source": [
    "print(lr.predict_proba(train_bream_smelt[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aba6d5f",
   "metadata": {},
   "source": [
    "샘플마다 2개의 확률이 출력되었다. 첫 번째 열이 음성 클래스(0)에 대한 확률이고 두 번째 열이 양성 클래스(1)에 대한 확률이다. 그럼 Bream과 Smelt중에 어떤 것이 양성 클래스일까? 앞서 k-최근접 이웃 분류기에서 보았듯이 사이킷런은 타깃값을 알파벳순으로 정렬하여 사용한다. classes_속성에서 확인해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9542fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bream' 'Smelt']\n"
     ]
    }
   ],
   "source": [
    "print(lr.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5e3dfe",
   "metadata": {},
   "source": [
    "빙어(smelt)가 양성 클래스다. predict_proba() 메서드가 반환한 배열 값을 보면 두 번째 샘플만 양성 클래스인 빙어의 확률이 높다. 나머지는 모두 도미(Bream)로 예측하겠다.\n",
    "\n",
    "- 만약 도미(Bream)을 양성 클래스로 사용하려면 어떻게 해야 할까? 2장에서 했던 것처럼 Bream인 타깃값을 1로 만들고 나머지 타깃값은 0으로 만들어 사용하면 된다.\n",
    "\n",
    "로지스틱 회귀로 성공적인 이진 분류를 수행했다. 그럼 선형 회귀에서처럼 로지스틱 회귀가 학습한 계수를 확인해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25550575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.4037798  -0.57620209 -0.66280298 -1.01290277 -0.73168947]] [-2.16155132]\n"
     ]
    }
   ],
   "source": [
    "print(lr.coef_, lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948be45d",
   "metadata": {},
   "source": [
    "확실히 로지스틱 회귀는 선형 회귀와 매우 비슷하다. 그럼 LogisticRegression 모델로 z 값을 계산해 볼 수 있을까? 가능하다. LogisticRegression 클래스는 decision_function() 메서드로 z 값을 출력할 수 있다. train_bream_smelt의 처음 5개 샘플의 z 값을 출력해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ffcfb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.02927744  3.57123907 -5.26568906 -4.24321775 -6.0607117 ]\n"
     ]
    }
   ],
   "source": [
    "decisions = lr.decision_function(train_bream_smelt[:5])\n",
    "print(decisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3ffab5",
   "metadata": {},
   "source": [
    "이 z값을 시그모이드 함수에 통과시키면 확률을 얻을 수 있다. 다행히 파이썬의 사이파이(scipy) 라이브러리에서도 시그모이드 함수가 있다. 바로 expit()이다. np.exp()함수를 사용해 분수 계산을 하는 것보다 훨씬 편리하고 안전하다. decisions 배열의 값을 확률로 변환해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17862482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00240145 0.97264817 0.00513928 0.01415798 0.00232731]\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import expit\n",
    "print(expit(decisions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bdbbbe",
   "metadata": {},
   "source": [
    "출력된 값을 보면 predict_proba() 메서드 출력의 두 번째 열의 값과 동일하다. 즉 decision_function() 메서드는 양성 클래스에 대한 z값을 반환한다.\n",
    "\n",
    "좋다. 아주 훌륭하다. 이진 분류를 위해 2개의 생선 샘플을 골라냈고 이를 사용해 로지스틱 회귀 모델을 훈련했다. 이진 분류일 경우 predict_proba()메서드는 음성 클래스와 양성 클래스에 대한 확률을 출력한다. 또 decision_function() 메서드는 양성 클래스에 대한 z 값을 계산한다. 또 coef_ 속성과 intercept_ 속성에는 로지스틱 모델이 학습한 선형 방정식의 계수가 들어 있다.\n",
    "\n",
    "이제 이진 분류의 경험을 바탕으로 7개의 생선을 분류하는 다중 분류 문제로 넘어가 보자.\n",
    "\n",
    "> 로지스틱 회귀로 다중 분류 수행하기\n",
    "\n",
    "앞에서 이진 분류를 위해 로지스틱 회귀 모델을 훈련시켜 보았다. 다중 분류도 크게 다르지 않다. 여기에서도 LogisticRegression 클래스는 기본적으로 반복적인 알고리즘을 사용한다. max_iter 매개변수에서 반복 횟수를 지정하며 기본값은 100이다. 여기에 준비한 데이터셋을 사용해 모델을 훈련하면 반복 횟수가 부족하다는 경고가 발생한다. 충분하게 훈련시키기 위해 반복 횟수를 1,000으로 늘리겠다.\n",
    "\n",
    "또 LogisticRression은 기본적으로 릿지 회귀와 같이 계수의 제곱을 규제한다. 이런 규제를 L2 규제라고도 부른다. 릿지 회귀에서는 alpha 매개변수로 규제의 양을 조절했다. alpha가 커지면 규제도 커진다. LogisticRergession에서 규제를 제어하는 매개변수는 C이다. 하지만 C 는 alpha와 반대로 작을수록 규제가 커진다. C의 기본값은 1이다. 여기에서는 규제를 조금 완하하기 위해 20으로 늘리겠다.\n",
    "\n",
    "다음 코드는 LogisticRegression 클래스로 다중 분류 모델을 훈련하는 코드이다. 7개의 생선 데이터가 모두 들어 있는 train_scaled와 train_target을 사용한 점을 눈여겨 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c1c6fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9327731092436975\n",
      "0.925\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression (C=20, max_iter=1000)\n",
    "lr.fit(train_scaled, train_target)\n",
    "print(lr.score(train_scaled, train_target))\n",
    "print(lr.score(test_scaled, test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f19b357",
   "metadata": {},
   "source": [
    "훈련 세트와 테스트 세트에 대한 점수가 높고 과대적합이나 과소적합으로 치우친 것 같지 않다. 좋다. 그럼 테스트 세트의 처음 5개 샘플에 대한 예측을 출력해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "994686c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Perch' 'Smelt' 'Pike' 'Roach' 'Perch']\n"
     ]
    }
   ],
   "source": [
    "print(lr.predict(test_scaled[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f7235b",
   "metadata": {},
   "source": [
    "이번에는 테스트 세트의 처음 5개 샘플에 대한 예측 확률을 출력해 보자.출력을 간소하게 하기 위해 소수점 네 번째 자리에서 반올림 하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd93b208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.014 0.841 0.    0.136 0.007 0.003]\n",
      " [0.    0.003 0.044 0.    0.007 0.946 0.   ]\n",
      " [0.    0.    0.034 0.935 0.015 0.016 0.   ]\n",
      " [0.011 0.034 0.306 0.007 0.567 0.    0.076]\n",
      " [0.    0.    0.904 0.002 0.089 0.002 0.001]]\n"
     ]
    }
   ],
   "source": [
    "proba = lr.predict_proba(test_scaled[:5])\n",
    "print(np.round(proba, decimals=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd174697",
   "metadata": {},
   "source": [
    "와우, 많은 숫자가 출력되었다. 5개 샘플에 대한 예측이므로 5개의 행이 출력되었다. 또 7개 생선에 대한 확률을 계산했으므로 7개의 열이 출력되었다. 이진 분류일 경우 2개의 열만 있었다는 것을 기억하자.\n",
    "\n",
    "첫 번째 샘플을 보면 세 번째 열의 확률이 가장 높다. 84.1%나 된다. 세 번째 열이 농어(Perch)에 대한 확률일까? classes_ 속성에서 클래스 정보를 확인해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d52dd9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bream' 'Parkki' 'Perch' 'Pike' 'Roach' 'Smelt' 'Whitefish']\n"
     ]
    }
   ],
   "source": [
    "print(lr.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f42934",
   "metadata": {},
   "source": [
    "네, 맞다. 첫 번째 샘플은 Perch를 가장 높은 확률로 예측했다. 두 번째 샘플은 여섯 번째 열인 Smelt를 가장 높은 확률(94.6%)로 예측했다.\n",
    "\n",
    "다중 분류도 어렵지 않다. 이진 분류는 샘플마다 2개의 확률을 출력하고 다중 분류는 샘플마다 클래스 개수만큼 확률을 출력한다. 여기에서는 7개이다. 이 중에서 가장 높은 확률이 예측 클래스가 된다.\n",
    "\n",
    "그럼 다중 분류일 경우 선형 방정식은 어떤 모습일까? coef_, intercept_ 의 크기를 출력해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b3f1809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 5) (7,)\n"
     ]
    }
   ],
   "source": [
    "print(lr.coef_.shape, lr.intercept_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340e2b1b",
   "metadata": {},
   "source": [
    "이 데이터는 5개의 특성을 사용하므로 coef_ 배열의 열은 5개이다. 그런데 행이 7이다. intercept_도 7개나 있다. 이 말은 이진 분류에서 보았던 z를 7개나 계산한다는 의미이다. 혹시 눈치 챘나? 다중 분류는 클래스마다 z 값을 하나씩 계산한다. 당연히 가장 높은 z 값을 출력하는 클래스가 예측 클래스가 된다. 그럼 확률은 어떻게 계산한 것일까? 이진 분류에서는 시그모이드 함수를 사용해 z를 0과 1사이의 값으로 변환했다. 다중 분류는 이와 달리 **소프트맥스 softmax** 함수를 사용하여 7개의 z값을 확률로 변환한다.\n",
    "\n",
    "- 소프트맥스 함수란?\n",
    "    - 시그모이드 함수는 하나의 선형 방정식의 출력값을 0~1사이로 압축한다. 이와 달리 소프트맥스 함수는 여러 개의 선형 방정식의 출력값을 0~1사이로 압축하고 전체 합이 1이 되도록 만든다. 이를 위해 지수 함수를 사용하기 때문에 **정규화된 지수 함수**라고도 부른다.\n",
    "    \n",
    "- 시그모이드 함수와 소프트맥스 함수가 중요한가?\n",
    "    - 시그모이드 함수와 소프트맥스 함수를 왜 이렇게 자세히 공부하는지 궁금할 수 있다. 사이킷런에서 자동으로 계산해 주지만 이 두함수는 나중에 신경망을 배울 때 또다시 등장한다. 여기에서 자세히 익혀두면 나중에 신경망을 배울 때 훨 씬 더 잘 이해할 수 있다.\n",
    "    \n",
    "    \n",
    "그럼 이진 분류에서처럼 decision_function() 메서드로 z1 ~ z7까지의 값을 구한 다음 소프트맥스 함수를 사용해 확률로 바꾸어 보겠다. 먼저 테스트 세트의 처음 5개 샘플에 대한 z1 ~ z7의 값을 구해보자.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6547d197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -6.5    1.03   5.16  -2.73   3.34   0.33  -0.63]\n",
      " [-10.86   1.93   4.77  -2.4    2.98   7.84  -4.26]\n",
      " [ -4.34  -6.23   3.17   6.49   2.36   2.42  -3.87]\n",
      " [ -0.68   0.45   2.65  -1.19   3.26  -5.75   1.26]\n",
      " [ -6.4   -1.99   5.82  -0.11   3.5   -0.11  -0.71]]\n"
     ]
    }
   ],
   "source": [
    "decision = lr.decision_function(test_scaled[:5])\n",
    "print(np.round(decision, decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4354f180",
   "metadata": {},
   "source": [
    "역시 사이파이는 소프트맥스 함수도 제공한다. scipy.special 아래에 softmax()함수를 임포트해 사용하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "312408a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.014 0.841 0.    0.136 0.007 0.003]\n",
      " [0.    0.003 0.044 0.    0.007 0.946 0.   ]\n",
      " [0.    0.    0.034 0.935 0.015 0.016 0.   ]\n",
      " [0.011 0.034 0.306 0.007 0.567 0.    0.076]\n",
      " [0.    0.    0.904 0.002 0.089 0.002 0.001]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "proba = softmax(decision, axis=1)\n",
    "print(np.round(proba, decimals=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba76e70",
   "metadata": {},
   "source": [
    "앞서 구한 decision 배열을 softmax()함수에 전달했다. softmax()의 axis 매개변수는 소프트맥스를 계산할 축을 지정한다. 여기에서는 axis=1로 지정하여 각 행, 즉 각 샘플에 대한 소프트맥스를 계산한다. 만약 axis 매개변수를 지정하지 않으면 배열 전체에 대해 소프트맥스를 계산한다.\n",
    "\n",
    "출력 결과를 앞서 구한 proba 배열과 비교해 보자. 결과가 정확히 일치한다. 성공이다. 로지스틱 회귀를 사용해 7개의 생선에 대한 확률을 예측하는 모델을 훈련했다. 이런 확률 값을 사용자에게 보여줄 수 있다면 마케팅 팀과 고객 만족팀을 모두 만족시킬 수 있겠다.\n",
    "\n",
    "\n",
    "### 로지스틱 회귀로 확률 예측 - 문제해결 과정\n",
    "\n",
    "럭키백에 담긴 생선이 어떤 생선인지 확률을 예측하는 문제였다. 분류 모델은 예측뿐만 아니라 예측의 근거가 되는 확률을 출력할 수 있다. 어찌 보면 이 확률은 분류 모델이 얼마나 예측을 확신하는지 나타낸다. 확률이 높을수록 강하게 예측하는 셈이다.\n",
    "\n",
    "k-최근접 이웃 모델이 확률을 출력할 수 있지만 이웃한 샘플의 클래스 비율이므로 항상 정해진 확률만 출력한다. 이는 마케팅 팀의 요구사항을 만족시킬 수 없을 것 같다. 고객이 어느 정도 생선을 예상할 수 있지만 상품마다 좀 더 그럴싸한 확률을 표시했으면 한다.\n",
    "\n",
    "이를 위해 가장 대표적인 분류 알고리즘 중 하나인 로지스틱 회귀를 사용했다. 로지스틱 회귀는 회귀 모델이 아닌 분류 모델이다. 선형 회귀처럼 선형 방정식을 사용한다. 하지만 선형 회귀처럼 계산한 값을 그대로 출력하는 것이 아니라 로지스틱 회귀는 이 값을 0 ~ 1 사이로 압축한다. 우리는 이 값을 마치 0 ~ 100% 사이의 확률로 이해할 수 있다.\n",
    "\n",
    "로지스틱 회귀는 이진분류에서는 하나의 선형 방정식을 훈련한다. 이 방정식의 출력값을 시그모이드 함수에 통과시켜 0 ~ 1사이의 값을 만든다. 이 값이 양성 클래스에 대한 확률이다. 음성 클래스의 확률은 1에서 양성 클래스의 확률을 빼면 된다.\n",
    "\n",
    "다중 분류일 경우에는 클래스 개수만큼 방정식을 훈련한다. 그 다음 각 방정식의 출력값을 소프트맥스 함수를 통과시켜 전체 클래스에 대한 합이 항상 1이 되도록 만든다. 이 값을 각 클래스에 대한 확률로 이해할 수 있다.\n",
    "\n",
    "다음 절에서는 인기가 높고 성능이 뛰어난 또 다른 머신러닝 알고리즘인 확률적 경사 하강법에 대해 배워보겠다.\n",
    "\n",
    "\n",
    "> 전체 소스 코드\n",
    "\n",
    "- https://bit.ly/hg-04-1 에 접속하면 코랩에서 이 절의 코드를 바로 열어 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee5317ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diagonal</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bream</td>\n",
       "      <td>242.0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.5200</td>\n",
       "      <td>4.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bream</td>\n",
       "      <td>290.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>31.2</td>\n",
       "      <td>12.4800</td>\n",
       "      <td>4.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bream</td>\n",
       "      <td>340.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.3778</td>\n",
       "      <td>4.6961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bream</td>\n",
       "      <td>363.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>12.7300</td>\n",
       "      <td>4.4555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bream</td>\n",
       "      <td>430.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.4440</td>\n",
       "      <td>5.1340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Species  Weight  Length  Diagonal   Height   Width\n",
       "0   Bream   242.0    25.4      30.0  11.5200  4.0200\n",
       "1   Bream   290.0    26.3      31.2  12.4800  4.3056\n",
       "2   Bream   340.0    26.5      31.1  12.3778  4.6961\n",
       "3   Bream   363.0    29.0      33.5  12.7300  4.4555\n",
       "4   Bream   430.0    29.0      34.0  12.4440  5.1340"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 데이터 준비하기\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "fish = pd.read_csv('https://bit.ly/fish_csv_data')\n",
    "fish.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d37a2be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bream' 'Roach' 'Whitefish' 'Parkki' 'Perch' 'Pike' 'Smelt']\n"
     ]
    }
   ],
   "source": [
    "print(pd.unique(fish['Species']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9644627",
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_input = fish[['Weight','Length','Diagonal','Height','Width']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9547d8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[242.      25.4     30.      11.52     4.02  ]\n",
      " [290.      26.3     31.2     12.48     4.3056]\n",
      " [340.      26.5     31.1     12.3778   4.6961]\n",
      " [363.      29.      33.5     12.73     4.4555]\n",
      " [430.      29.      34.      12.444    5.134 ]]\n"
     ]
    }
   ],
   "source": [
    "print(fish_input[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "84fac57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_target = fish['Species'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "544e2de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(\n",
    "    fish_input, fish_target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fbb7299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_input)\n",
    "train_scaled = ss.transform(train_input)\n",
    "test_scaled = ss.transform(test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b656059",
   "metadata": {},
   "source": [
    "k-최근접 이웃 분류기의 확률 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "404b3374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8907563025210085\n",
      "0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "kn = KNeighborsClassifier(n_neighbors=3)\n",
    "kn.fit(train_scaled, train_target)\n",
    "\n",
    "print(kn.score(train_scaled, train_target))\n",
    "print(kn.score(test_scaled, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f8f8be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bream' 'Parkki' 'Perch' 'Pike' 'Roach' 'Smelt' 'Whitefish']\n"
     ]
    }
   ],
   "source": [
    "print(kn.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bdcba74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Perch' 'Smelt' 'Pike' 'Perch' 'Perch']\n"
     ]
    }
   ],
   "source": [
    "print(kn.predict(test_scaled[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "64aff0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Perch' 'Smelt' 'Pike' 'Perch' 'Perch']\n"
     ]
    }
   ],
   "source": [
    "print(kn.predict(test_scaled[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d28a750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Roach' 'Perch' 'Perch']]\n"
     ]
    }
   ],
   "source": [
    "distances, indexes = kn.kneighbors(test_scaled[3:4])\n",
    "print(train_target[indexes])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcee102",
   "metadata": {},
   "source": [
    "로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6d3b441a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "z = np.arange(-5, 5, 0.1)\n",
    "phi = 1 / (1 + np.exp(-z))\n",
    "\n",
    "plt.plot(z, phi)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('phi')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f54fd5",
   "metadata": {},
   "source": [
    "로지스틱 회귀로 이진 분류 수행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "104ab9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A' 'C']\n"
     ]
    }
   ],
   "source": [
    "char_arr = np.array(['A', 'B', 'C', 'D', 'E'])\n",
    "print(char_arr[[True, False, True, False, False]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "83720c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "bream_smelt_indexes = (train_target == 'Bream') | (train_target == 'Smelt')\n",
    "train_bream_smelt = train_scaled[bream_smelt_indexes]\n",
    "target_bream_smelt = train_target[bream_smelt_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "82952c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_bream_smelt, target_bream_smelt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d899a982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bream' 'Smelt' 'Bream' 'Bream' 'Bream']\n"
     ]
    }
   ],
   "source": [
    "print(lr.predict(train_bream_smelt[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ddbca0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99759855 0.00240145]\n",
      " [0.02735183 0.97264817]\n",
      " [0.99486072 0.00513928]\n",
      " [0.98584202 0.01415798]\n",
      " [0.99767269 0.00232731]]\n"
     ]
    }
   ],
   "source": [
    "print(lr.predict_proba(train_bream_smelt[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b68df4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bream' 'Smelt']\n"
     ]
    }
   ],
   "source": [
    "print(lr.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a2234b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.4037798  -0.57620209 -0.66280298 -1.01290277 -0.73168947]] [-2.16155132]\n"
     ]
    }
   ],
   "source": [
    "print(lr.coef_, lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8715881e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.02927744  3.57123907 -5.26568906 -4.24321775 -6.0607117 ]\n"
     ]
    }
   ],
   "source": [
    "decisions = lr.decision_function(train_bream_smelt[:5])\n",
    "print(decisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bb7de056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00240145 0.97264817 0.00513928 0.01415798 0.00232731]\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "print(expit(decisions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63e5f76",
   "metadata": {},
   "source": [
    "로지스틱 회귀로 다중 분류 수행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6ec74c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9327731092436975\n",
      "0.925\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=20, max_iter=1000)\n",
    "lr.fit(train_scaled, train_target)\n",
    "\n",
    "print(lr.score(train_scaled, train_target))\n",
    "print(lr.score(test_scaled, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fbf8b938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Perch' 'Smelt' 'Pike' 'Roach' 'Perch']\n"
     ]
    }
   ],
   "source": [
    "print(lr.predict(test_scaled[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "482451e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.014 0.841 0.    0.136 0.007 0.003]\n",
      " [0.    0.003 0.044 0.    0.007 0.946 0.   ]\n",
      " [0.    0.    0.034 0.935 0.015 0.016 0.   ]\n",
      " [0.011 0.034 0.306 0.007 0.567 0.    0.076]\n",
      " [0.    0.    0.904 0.002 0.089 0.002 0.001]]\n"
     ]
    }
   ],
   "source": [
    "proba = lr.predict_proba(test_scaled[:5])\n",
    "print(np.round(proba, decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9439169f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bream' 'Parkki' 'Perch' 'Pike' 'Roach' 'Smelt' 'Whitefish']\n"
     ]
    }
   ],
   "source": [
    "print(lr.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0955b9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 5) (7,)\n"
     ]
    }
   ],
   "source": [
    "print(lr.coef_.shape, lr.intercept_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "19133b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -6.5    1.03   5.16  -2.73   3.34   0.33  -0.63]\n",
      " [-10.86   1.93   4.77  -2.4    2.98   7.84  -4.26]\n",
      " [ -4.34  -6.23   3.17   6.49   2.36   2.42  -3.87]\n",
      " [ -0.68   0.45   2.65  -1.19   3.26  -5.75   1.26]\n",
      " [ -6.4   -1.99   5.82  -0.11   3.5   -0.11  -0.71]]\n"
     ]
    }
   ],
   "source": [
    "decision = lr.decision_function(test_scaled[:5])\n",
    "print(np.round(decision, decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "77565450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.014 0.841 0.    0.136 0.007 0.003]\n",
      " [0.    0.003 0.044 0.    0.007 0.946 0.   ]\n",
      " [0.    0.    0.034 0.935 0.015 0.016 0.   ]\n",
      " [0.011 0.034 0.306 0.007 0.567 0.    0.076]\n",
      " [0.    0.    0.904 0.002 0.089 0.002 0.001]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "proba = softmax(decision, axis=1)\n",
    "print(np.round(proba, decimals=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddf14d4",
   "metadata": {},
   "source": [
    "## 04-2 확률적 경사 하강법\n",
    "\n",
    "- 핵심 키워드\n",
    "    - 확률적 경사 하강법\n",
    "    - 손실 함수\n",
    "    - 에포크\n",
    "    - 경사 하강법 알고리즘을 이해하고 대량의 데이터에서 분류 모델을 훈련하는 방법을 배운다.\n",
    "    \n",
    "#### 점진적인 학습\n",
    "\n",
    "문제: 영업팀은 매주 7개의 생선 중에서 일부를 무작위로 골라 머신러닝 모델을 학습할 수 있게 훈련데이터를 제공하고있다. 하지만 수산물을 고급하겠다는 곳이 너무 많아 샘플을 골라내는 일이 너무 힘들다. 하지만 수산물을 공급하겠다는 곳이 너무 많아 샘플을 골라내는 일이 너무 힘들다. 게다가 추가되는 수산물은 아직 샘플을 가지고 있지도 않는다. 영업 팀은 새로운 생선이 도착하는 대로 가능한 즉시 훈련 데이터를 제공하겠다고 약속했다. 하지만 어느 생선이 먼저 올지도, 모든 생선이 도착할 때까지 기다릴 수도 없다. 이제 어떻게 해야 할까?\n",
    "\n",
    "훈련 데이터가 한 번에 준비되는 것이 아니라 조금씩 전달된다는 것이다. 도착하는 대로 생선을 판매해야 하므로 데이터가 쌓일 때까지 무작정 기다릴 수도 없다. 그렇다면 기존의 훈련 데이터에 새로운 데이터를 추가하여 모델을 매일매일 다시 훈련하면 어떨까?\n",
    "\n",
    "괜찮은 아이디어이다. 이렇게 하면 매일 추가되는 새로운 데이터를 활용해 모델을 훈련할 수 있다. 한 가지 단점은 시간이 지날수록 데이터가 늘어나는 것이다. 처음 며칠은 괜찮겠지만, 몇달이 지나면 모델을 훈련하기 위해 서버를 늘려야 한다. 만약 몇 년이 지난다면... 확실히 지속 가능한 방법은 아닌 것 같다.\n",
    "\n",
    "또 다른 방법은 새로운 데이터를 추가할 때 이전 데이터를 버림으로써 후련 데이터 크기를 일정하게 유지하는 것이다. 이렇게 하면 데이터셋의 크기가 너무 커지지 않을 수 있다. 하지만 데이터를 버릴 때 다른 데이터에 없는 중요한 생선 데이터가 포함되어 있다면 큰일이다. 앞으로 모델이 그 생선을 제대로 예측하지 못할 테니까요. 흠, 더 좋은 방법이 없을까?\n",
    "\n",
    "위에서 언급한 방법은 이전에 훈련한 모델을 버리고 다시 새로운 모델을 훈련하는 방식이다. 앞서 훈련한 모델을 버리지 않고 새로운 데이터에 대해서만 조금씩 더 훈련할 수 없을까? 이렇게 할 수 있다면 훈련에 사용한 데이터를 모두 유지할 필요도 없고 앞서 학습한 생선을 까먹을 일도 없을 것이다.\n",
    "\n",
    "이런 식의 훈련 방식을 **점진적 학습** 또는 온라인 학습이라고 부른다. 대표적인 점진적 학습 알고리즘은 **확률적 경사 하강법 Stochastic Gradient Descent** 이다. 물론 사이킷런에서도 확률적 경사 하강법을 위한 클래스를 제공한다. 확률적 경사 하강법을 사용하기 전에 어떤 알고리즘인지, 또 왜 중요한지에 대해 먼저 알아보겠다.\n",
    "\n",
    "> 확률적 경사 하강법\n",
    "\n",
    "확률적 경사 하강법에서 확률적이란 말은 '무작위하게' 혹은 '랜덤하게' 의 기술적인 표현이다. 이 의미는 조금 나중에 다시 살펴보겠다. 그다음 '경사'는 '이 언덕은 경사가 참 가파르군!' 할 때 그 경사이다. 즉 기울기를 말하는 것이다. '하강법'은 '내려가는 방법'이다. 다시 말해 경사 하강법은 경사를 따라 내려가는 방법을 말한다. 산에서 내려온다고 생각해보자. 집으로 돌어가려면 등산로 입구까지 내려가야 한다. 만약 어떤 산길로 척척 내려갈 수 있는 초능력이 있다면 가장 빠른 길을 선택하는 것이 좋겠다. 가장 빠른 길은 경사가 가장 가파른 길이다.!\n",
    "\n",
    "경사 하강법이 바로 이런 방식이다. 가장 가파른 경사를 따라 원하는 지점에 도달하는 것이 목표이다. 하지만 가제트 형사의 긴 다리를 생각해보자. 만약 한번에 걸음이 너무 크면 경사를 따라 내려가지 못하고 오히려 올라갈 수가 있다.\n",
    "\n",
    "조금 과장되었지만, 실제로 산에서 내려올 때는 천천히 조금씩 내려와야한다. 나뭇잎 속에 가려진 웅덩이가 있을지도 모르니까.. 경사 하강법도 마찬가지이다. 가장 가파른 길을 찾아 내려오지만 조금씩 내려오는 것이 중요하다. 이렇게 내려오는 과정이 바로 경사 하강법 모델을 훈련하는 것이다.\n",
    "\n",
    "좋다. 그럼 이제 **확률적** 이란 말을 이해할 차례이다. 경사 하강법으로 내려올때 가장 가파른 길을 찾는 방법을 무엇일까? 훈련 세트를 사용해 모델을 훈련하기 때문에 경사 하강법도 당연히 훈련 세트를 사용하여 가장 가파른 길을 찾을 것이다. 그런데 전체 샘플을 사용하지 않고 딱 하나의 샘플을 훈련 세트에서 랜덤하게 골라 가장 가파른 길을 찾자! 이처럼 훈련 세트에서 랜덤하게 하나의 샘플을 고르는 것이 바로 **확률적 경사 하강법** 이다.\n",
    "\n",
    "조금 더 자세히 설명하면 다음과 같다. 확률적 경사 하강법은 훈련 세트에서 랜덤하게 하나의 샘플을 선택하여 가파른 경사를 조금 내려간다. 그다음 훈련 세트에서 랜덤하게 또 다른 샘플을 하나 선택하여 경사를 조금 내려간다. 이런 식으로 전체 샘플을 모두 사용할때 까지 계속한다.\n",
    "\n",
    "이제 모든 샘플을 다 사용했다. 그래도 산을 다 내려오지 못했으면 어떻게 할까? 간단하다. 다시 처음부터 시작하는 것이다. 훈련 세트에 모든 샘플을 다시 채워 넣는다. 그다음 다시 랜검하게 하나의 샘플을 선택해 이어서 경사를 내려간다. 이렇게 만족할만한 위치에 도달할 때까지 계속 내려가면 된다. 확률적 경사 하강법에서 훈련 세트를 한 번 모두 사용하는 과정을 **에포크 epoch**라고 부른다. 일반적으로 경사 하강법은 수십, 수백 번 이상 에포크를 수행한다.\n",
    "\n",
    "아니 무작위로 샘플을 선택해 산에서 내려가다니 너무 무택임한 것 아닐까? 그래서 아주 조금씩 내려가야 한다. 하지만 걱정하는 것과는 달리 확률적 경사 하강법은 꽤 잘 동작한다. 만약 그래도 걱정이 된다면 1개씩 말고 무작위로 몇개의 샘플을 선택해서 경사를 따라 내려가면 어떨까? 가능하다. 이렇게 여러 개의 샘플을 사용해 경사 하강법을 수행하는 방식을 **미니배치 경사 하강법 minibatch gradient descent** 이라고 한다. 실전에서 아주 많이 사용한다.\n",
    "\n",
    "극단적으로 한 번 경사로를 따라 이동하기 위해 전체 샘플을 사용할 수도 있다. 이를 **배치 경사 하강법 batch gradient descent** 라고 부른다. 사실 전체 데이터를 사용하기 때문에 가장 안정적인 방법이 될 수 있다. 하지만 전체 데이터를 사용하면 그만큼 컴퓨터 자원을 많이 사용하게 된다. 어떤 경우는 데이터가 너무너무 많아 한 번에 전체 데이터를 모두 읽을 수 없을지도 모른다.\n",
    "\n",
    "확률적 경사 하강법은 훈련 세트를 사용해 산 아래에 있는 최적의 장소로 조금씩 이동하는 알고리즘이다. 이 때문에 훈련 데이터가 모두 준비되어 있지 않고 매일매일 업데이트 되어도 학습을 계속 이어 나갈 수 있다. 즉 다시 산꼭대기에서부터 시작할 필요가 없다.\n",
    "\n",
    "- 확률적 경사 하강법과 신경망 알고리즘\n",
    "    - 확률적 경사 하강법을 꼭 사용하는 알고리즘이 있다. 바로 신경망 알고리즘이다. 신경망은 일반적으로 많은 데이터를 사용하기 때문에 한 번에 모든 데이터를 사용하기 어렵다. 또 모델이 매우 복잡하기 때문에 수학적인 방법으로 해답을 얻기 어렵다. 신경망 모델이 확률적 경사 하강법이나 미니배치 경사 하강법을 사용한다는 점을 꼭 기억하자.\n",
    "    \n",
    "그런데 어디서 내려야 할까? 다시 말해 가장 빠른 길을 찾아 내려가려고 하는 이 산은 도대체 무엇일까? 이 산이 바로 손실 함수라 부르는 것이다.\n",
    "\n",
    "\n",
    "#### 손실함수\n",
    "\n",
    "**손실함수 loss function** 는 어떤 문제에서 머신러닝 알고리즘이 얼마나 엉터리인지를 측정하는 기준이다. 그렇다면 손실 함수의 값이 작을 수록 좋다. 하지만 어떤 값이 최솟값인지는 알지 못한다. 가능한 많이 찾아보고 만족할만한 수준이라면 산을 다 내려왔다고 인정해야 한다. 이 값을 찾아서 조금씩 이동하려면 확률적 경사 하강법이 잘 맞을 것 같다.\n",
    "\n",
    "다행히 우리가 다루는 많은 문제에 필요한 손실 함수는 이미 정의되어 있다. 그럼 생선을 분류하기 위해서는 어떤 손실 함수를 사용하는지 알아보자.\n",
    "\n",
    "- 손실 함수와 비용 함수\n",
    "    - 비용 함수(cost function)는 손실 함수의 다른 말이다. 엄밀히 말하면 손실 함수는 샘플 하나에 대한 손실을 정의하고 비용 함수는 훈련 세트에 있는 모든 샘플에 대한 손실 함수의 합을 말한다. 하지만 보통 이 둘을 엄격히 구분하지 않고 섞어서 사용한다.\n",
    "    \n",
    "분류에서 손실은 아주 확실하다. 정답을 못 맞히는 거다. 이해를 돕기위해 도미와 빙어를 구분하는 이진 분류 문제를 예로 들어보겠다. 도미는 양성클래스(1), 빙어는 음성 클래스(0)라고 가정해보자. 4개의 예측 중에 2개만 맞았으므로 정확도는 1/2=0.5이다. 정확도를 손실 함수로 사용할 수 있을까? 예를 들어 정확도에 음수를 취하면 -1.0이 가장 낮고 -0.0이 가장 높다. 손실 함수로 괜찮지 않을까?\n",
    "\n",
    "하지만 정확도는 0, 0.25, 0.5, 0.75, 1 다섯 가지뿐이다. 앞에서 경사 하강법을 사용할 때 아주 조금씩 내려온다고 했던 말을 기억하나? 정확도가 이렇게 듬성듬성하다면 경사 하강법을 이용해 조금씩 움직일 수 없다. 산의 경사면은 확실히 연속적이어야 한다.\n",
    "\n",
    "- 기술적으로 말하면 손실 함수는 미분 가능해야 합니다. 여기서는 독자들이 이해하기 쉽도록 최대한 비유를 사용했다.\n",
    "\n",
    "그럼 어떻게 연속적인 손실 함수를 만들 수 있을까? 1절 '로지스틱 회귀'에서 로지스틱 회귀 모델이 확률을 출력한 것을 기억하나? 예측은 0또는 1이지만 확률은 0 ~ 1 사이의 어떤 값도 될 수 있다. 즉 연속적이다. 가령 위의 샘플 4개의 예측 확률을 각각 0.9, 0.3, 0.2, 0.8 이라고 가정해 보자. 첫 번째 샘플부터 하나씩 어떻게 손실 함수를 만들 수 있는지 살펴보자.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc22aa53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
